{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d1add3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gantrainer import GANTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2493e5d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./cifar10/\n",
      "Data Loaded\n",
      "\n",
      "Training GAN with\n",
      "-100 Latent Dimensions\n",
      "-for 1000 Epochs\n",
      "-with Batch Size of 256\n",
      "-up to 5 Retries\n",
      "\n",
      "Attempt:1\n",
      "Epoch: 1\n",
      "Try:1, Epoch:1, D_Loss_Real=0.287, D_Loss_Fake=0.588, D_Acc_Real=0.914, D_Acc_Fake=1.000, GAN_Loss=1.051\n",
      "\n",
      "Epoch: 2\n",
      "Try:1, Epoch:2, D_Loss_Real=0.101, D_Loss_Fake=0.723, D_Acc_Real=0.992, D_Acc_Fake=0.398, GAN_Loss=0.803\n",
      "\n",
      "Epoch: 3\n",
      "Try:1, Epoch:3, D_Loss_Real=0.029, D_Loss_Fake=0.240, D_Acc_Real=1.000, D_Acc_Fake=1.000, GAN_Loss=1.699\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 4\n",
      "Try:1, Epoch:4, D_Loss_Real=0.178, D_Loss_Fake=0.212, D_Acc_Real=0.914, D_Acc_Fake=1.000, GAN_Loss=2.130\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 5\n",
      "Try:1, Epoch:5, D_Loss_Real=0.713, D_Loss_Fake=1.249, D_Acc_Real=0.641, D_Acc_Fake=0.102, GAN_Loss=1.547\n",
      "\n",
      "Epoch: 6\n",
      "Try:1, Epoch:6, D_Loss_Real=0.180, D_Loss_Fake=0.115, D_Acc_Real=0.953, D_Acc_Fake=0.984, GAN_Loss=2.753\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 7\n",
      "Try:1, Epoch:7, D_Loss_Real=0.578, D_Loss_Fake=0.167, D_Acc_Real=0.695, D_Acc_Fake=1.000, GAN_Loss=2.540\n",
      "\n",
      "Epoch: 8\n",
      "Try:1, Epoch:8, D_Loss_Real=0.342, D_Loss_Fake=0.193, D_Acc_Real=0.875, D_Acc_Fake=0.984, GAN_Loss=2.136\n",
      "\n",
      "Epoch: 9\n",
      "Try:1, Epoch:9, D_Loss_Real=0.296, D_Loss_Fake=0.338, D_Acc_Real=0.883, D_Acc_Fake=0.836, GAN_Loss=2.358\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 10\n",
      "Try:1, Epoch:10, D_Loss_Real=0.742, D_Loss_Fake=0.451, D_Acc_Real=0.539, D_Acc_Fake=0.820, GAN_Loss=1.763\n",
      "\n",
      "Epoch: 11\n",
      "Try:1, Epoch:11, D_Loss_Real=0.468, D_Loss_Fake=0.543, D_Acc_Real=0.766, D_Acc_Fake=0.750, GAN_Loss=1.317\n",
      "\n",
      "Epoch: 12\n",
      "Try:1, Epoch:12, D_Loss_Real=0.540, D_Loss_Fake=0.808, D_Acc_Real=0.773, D_Acc_Fake=0.562, GAN_Loss=1.014\n",
      "\n",
      "Epoch: 13\n",
      "Try:1, Epoch:13, D_Loss_Real=0.636, D_Loss_Fake=0.497, D_Acc_Real=0.578, D_Acc_Fake=0.844, GAN_Loss=1.159\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 14\n",
      "Try:1, Epoch:14, D_Loss_Real=0.584, D_Loss_Fake=0.481, D_Acc_Real=0.734, D_Acc_Fake=0.922, GAN_Loss=1.151\n",
      "\n",
      "Epoch: 15\n",
      "Try:1, Epoch:15, D_Loss_Real=0.736, D_Loss_Fake=0.520, D_Acc_Real=0.445, D_Acc_Fake=0.867, GAN_Loss=1.096\n",
      "\n",
      "Epoch: 16\n",
      "Try:1, Epoch:16, D_Loss_Real=0.732, D_Loss_Fake=0.601, D_Acc_Real=0.477, D_Acc_Fake=0.711, GAN_Loss=1.002\n",
      "\n",
      "Epoch: 17\n",
      "Try:1, Epoch:17, D_Loss_Real=0.685, D_Loss_Fake=0.580, D_Acc_Real=0.539, D_Acc_Fake=0.711, GAN_Loss=1.081\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 18\n",
      "Try:1, Epoch:18, D_Loss_Real=0.615, D_Loss_Fake=0.527, D_Acc_Real=0.609, D_Acc_Fake=0.875, GAN_Loss=1.038\n",
      "\n",
      "Epoch: 19\n",
      "Try:1, Epoch:19, D_Loss_Real=0.626, D_Loss_Fake=0.544, D_Acc_Real=0.641, D_Acc_Fake=0.914, GAN_Loss=0.998\n",
      "\n",
      "Epoch: 20\n",
      "Try:1, Epoch:20, D_Loss_Real=0.598, D_Loss_Fake=0.681, D_Acc_Real=0.695, D_Acc_Fake=0.617, GAN_Loss=0.846\n",
      "\n",
      "Performance test> Accuracy real: 74%, fake: 53%\n",
      "(100, 32, 32, 3)\n",
      "0.0005874634\n",
      "254.99872\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch: 21\n",
      "Try:1, Epoch:21, D_Loss_Real=0.565, D_Loss_Fake=0.622, D_Acc_Real=0.766, D_Acc_Fake=0.758, GAN_Loss=1.092\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 22\n",
      "Try:1, Epoch:22, D_Loss_Real=0.651, D_Loss_Fake=0.798, D_Acc_Real=0.578, D_Acc_Fake=0.344, GAN_Loss=0.786\n",
      "\n",
      "Epoch: 23\n",
      "Try:1, Epoch:23, D_Loss_Real=0.651, D_Loss_Fake=0.727, D_Acc_Real=0.641, D_Acc_Fake=0.469, GAN_Loss=0.841\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 24\n",
      "Try:1, Epoch:24, D_Loss_Real=0.673, D_Loss_Fake=0.674, D_Acc_Real=0.578, D_Acc_Fake=0.531, GAN_Loss=0.910\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 25\n",
      "Try:1, Epoch:25, D_Loss_Real=0.652, D_Loss_Fake=0.672, D_Acc_Real=0.586, D_Acc_Fake=0.586, GAN_Loss=0.926\n",
      "\n",
      "Generator loss increased for 3 epochs.\n",
      "Epoch: 26\n",
      "Try:1, Epoch:26, D_Loss_Real=0.603, D_Loss_Fake=0.484, D_Acc_Real=0.664, D_Acc_Fake=0.938, GAN_Loss=1.140\n",
      "\n",
      "Generator loss increased for 4 epochs.\n",
      "Epoch: 27\n",
      "Try:1, Epoch:27, D_Loss_Real=0.708, D_Loss_Fake=0.701, D_Acc_Real=0.508, D_Acc_Fake=0.609, GAN_Loss=0.930\n",
      "\n",
      "Epoch: 28\n",
      "Try:1, Epoch:28, D_Loss_Real=0.653, D_Loss_Fake=0.771, D_Acc_Real=0.586, D_Acc_Fake=0.375, GAN_Loss=0.797\n",
      "\n",
      "Epoch: 29\n",
      "Try:1, Epoch:29, D_Loss_Real=0.689, D_Loss_Fake=0.544, D_Acc_Real=0.531, D_Acc_Fake=0.797, GAN_Loss=0.996\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 30\n",
      "Try:1, Epoch:30, D_Loss_Real=0.581, D_Loss_Fake=0.631, D_Acc_Real=0.703, D_Acc_Fake=0.695, GAN_Loss=0.913\n",
      "\n",
      "Epoch: 31\n",
      "Try:1, Epoch:31, D_Loss_Real=0.581, D_Loss_Fake=0.617, D_Acc_Real=0.703, D_Acc_Fake=0.688, GAN_Loss=0.996\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 32\n",
      "Try:1, Epoch:32, D_Loss_Real=0.781, D_Loss_Fake=0.622, D_Acc_Real=0.406, D_Acc_Fake=0.680, GAN_Loss=1.026\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 33\n",
      "Try:1, Epoch:33, D_Loss_Real=0.695, D_Loss_Fake=0.810, D_Acc_Real=0.523, D_Acc_Fake=0.383, GAN_Loss=0.840\n",
      "\n",
      "Epoch: 34\n",
      "Try:1, Epoch:34, D_Loss_Real=0.727, D_Loss_Fake=0.584, D_Acc_Real=0.445, D_Acc_Fake=0.719, GAN_Loss=1.027\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 35\n",
      "Try:1, Epoch:35, D_Loss_Real=0.651, D_Loss_Fake=0.520, D_Acc_Real=0.656, D_Acc_Fake=0.875, GAN_Loss=1.034\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 36\n",
      "Try:1, Epoch:36, D_Loss_Real=0.561, D_Loss_Fake=0.732, D_Acc_Real=0.742, D_Acc_Fake=0.523, GAN_Loss=0.814\n",
      "\n",
      "Epoch: 37\n",
      "Try:1, Epoch:37, D_Loss_Real=0.748, D_Loss_Fake=0.682, D_Acc_Real=0.461, D_Acc_Fake=0.547, GAN_Loss=0.851\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 38\n",
      "Try:1, Epoch:38, D_Loss_Real=0.556, D_Loss_Fake=0.603, D_Acc_Real=0.734, D_Acc_Fake=0.773, GAN_Loss=1.024\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 39\n",
      "Try:1, Epoch:39, D_Loss_Real=0.703, D_Loss_Fake=0.597, D_Acc_Real=0.586, D_Acc_Fake=0.680, GAN_Loss=1.066\n",
      "\n",
      "Generator loss increased for 3 epochs.\n",
      "Epoch: 40\n",
      "Try:1, Epoch:40, D_Loss_Real=0.755, D_Loss_Fake=0.591, D_Acc_Real=0.484, D_Acc_Fake=0.797, GAN_Loss=0.950\n",
      "\n",
      "Performance test> Accuracy real: 52%, fake: 80%\n",
      "(100, 32, 32, 3)\n",
      "3.8146973e-05\n",
      "254.99826\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch: 41\n",
      "Try:1, Epoch:41, D_Loss_Real=0.667, D_Loss_Fake=0.618, D_Acc_Real=0.570, D_Acc_Fake=0.672, GAN_Loss=0.922\n",
      "\n",
      "Epoch: 42\n",
      "Try:1, Epoch:42, D_Loss_Real=0.568, D_Loss_Fake=0.615, D_Acc_Real=0.734, D_Acc_Fake=0.742, GAN_Loss=0.937\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 43\n",
      "Try:1, Epoch:43, D_Loss_Real=0.686, D_Loss_Fake=0.463, D_Acc_Real=0.562, D_Acc_Fake=0.945, GAN_Loss=1.149\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 44\n",
      "Try:1, Epoch:44, D_Loss_Real=0.536, D_Loss_Fake=0.704, D_Acc_Real=0.719, D_Acc_Fake=0.562, GAN_Loss=0.879\n",
      "\n",
      "Epoch: 45\n",
      "Try:1, Epoch:45, D_Loss_Real=0.688, D_Loss_Fake=0.553, D_Acc_Real=0.508, D_Acc_Fake=0.789, GAN_Loss=1.064\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 46\n",
      "Try:1, Epoch:46, D_Loss_Real=0.588, D_Loss_Fake=0.836, D_Acc_Real=0.695, D_Acc_Fake=0.367, GAN_Loss=0.704\n",
      "\n",
      "Epoch: 47\n",
      "Try:1, Epoch:47, D_Loss_Real=0.630, D_Loss_Fake=0.751, D_Acc_Real=0.641, D_Acc_Fake=0.523, GAN_Loss=0.873\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 48\n",
      "Try:1, Epoch:48, D_Loss_Real=0.684, D_Loss_Fake=0.689, D_Acc_Real=0.547, D_Acc_Fake=0.500, GAN_Loss=0.861\n",
      "\n",
      "Epoch: 49\n",
      "Try:1, Epoch:49, D_Loss_Real=0.753, D_Loss_Fake=0.708, D_Acc_Real=0.430, D_Acc_Fake=0.562, GAN_Loss=0.893\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 50\n",
      "Try:1, Epoch:50, D_Loss_Real=0.621, D_Loss_Fake=0.624, D_Acc_Real=0.664, D_Acc_Fake=0.664, GAN_Loss=0.899\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 51\n",
      "Try:1, Epoch:51, D_Loss_Real=0.785, D_Loss_Fake=0.655, D_Acc_Real=0.445, D_Acc_Fake=0.625, GAN_Loss=0.963\n",
      "\n",
      "Generator loss increased for 3 epochs.\n",
      "Epoch: 52\n",
      "Try:1, Epoch:52, D_Loss_Real=0.621, D_Loss_Fake=0.580, D_Acc_Real=0.641, D_Acc_Fake=0.773, GAN_Loss=0.993\n",
      "\n",
      "Generator loss increased for 4 epochs.\n",
      "Epoch: 53\n",
      "Try:1, Epoch:53, D_Loss_Real=0.647, D_Loss_Fake=0.741, D_Acc_Real=0.578, D_Acc_Fake=0.453, GAN_Loss=0.750\n",
      "\n",
      "Epoch: 54\n",
      "Try:1, Epoch:54, D_Loss_Real=0.738, D_Loss_Fake=0.619, D_Acc_Real=0.461, D_Acc_Fake=0.734, GAN_Loss=1.029\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 55\n",
      "Try:1, Epoch:55, D_Loss_Real=0.738, D_Loss_Fake=0.658, D_Acc_Real=0.469, D_Acc_Fake=0.648, GAN_Loss=0.896\n",
      "\n",
      "Epoch: 56\n",
      "Try:1, Epoch:56, D_Loss_Real=0.603, D_Loss_Fake=0.687, D_Acc_Real=0.727, D_Acc_Fake=0.523, GAN_Loss=0.778\n",
      "\n",
      "Epoch: 57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try:1, Epoch:57, D_Loss_Real=0.675, D_Loss_Fake=0.629, D_Acc_Real=0.531, D_Acc_Fake=0.672, GAN_Loss=0.983\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 58\n",
      "Try:1, Epoch:58, D_Loss_Real=0.648, D_Loss_Fake=0.633, D_Acc_Real=0.641, D_Acc_Fake=0.680, GAN_Loss=0.900\n",
      "\n",
      "Epoch: 59\n",
      "Try:1, Epoch:59, D_Loss_Real=0.712, D_Loss_Fake=0.694, D_Acc_Real=0.461, D_Acc_Fake=0.500, GAN_Loss=0.802\n",
      "\n",
      "Epoch: 60\n",
      "Try:1, Epoch:60, D_Loss_Real=0.641, D_Loss_Fake=0.678, D_Acc_Real=0.609, D_Acc_Fake=0.594, GAN_Loss=0.808\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Performance test> Accuracy real: 63%, fake: 54%\n",
      "(100, 32, 32, 3)\n",
      "0.011192322\n",
      "254.99979\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch: 61\n",
      "Try:1, Epoch:61, D_Loss_Real=0.634, D_Loss_Fake=0.607, D_Acc_Real=0.688, D_Acc_Fake=0.750, GAN_Loss=0.912\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 62\n",
      "Try:1, Epoch:62, D_Loss_Real=0.688, D_Loss_Fake=0.656, D_Acc_Real=0.570, D_Acc_Fake=0.641, GAN_Loss=0.864\n",
      "\n",
      "Epoch: 63\n",
      "Try:1, Epoch:63, D_Loss_Real=0.767, D_Loss_Fake=0.660, D_Acc_Real=0.438, D_Acc_Fake=0.625, GAN_Loss=0.875\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 64\n",
      "Try:1, Epoch:64, D_Loss_Real=0.734, D_Loss_Fake=0.502, D_Acc_Real=0.445, D_Acc_Fake=0.852, GAN_Loss=1.132\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 65\n",
      "Try:1, Epoch:65, D_Loss_Real=0.657, D_Loss_Fake=0.589, D_Acc_Real=0.586, D_Acc_Fake=0.797, GAN_Loss=0.970\n",
      "\n",
      "Epoch: 66\n",
      "Try:1, Epoch:66, D_Loss_Real=0.648, D_Loss_Fake=0.695, D_Acc_Real=0.648, D_Acc_Fake=0.508, GAN_Loss=0.782\n",
      "\n",
      "Epoch: 67\n",
      "Try:1, Epoch:67, D_Loss_Real=0.703, D_Loss_Fake=0.616, D_Acc_Real=0.477, D_Acc_Fake=0.695, GAN_Loss=0.904\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 68\n",
      "Try:1, Epoch:68, D_Loss_Real=0.642, D_Loss_Fake=0.660, D_Acc_Real=0.609, D_Acc_Fake=0.594, GAN_Loss=0.911\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 69\n",
      "Try:1, Epoch:69, D_Loss_Real=0.661, D_Loss_Fake=0.622, D_Acc_Real=0.562, D_Acc_Fake=0.688, GAN_Loss=0.913\n",
      "\n",
      "Generator loss increased for 3 epochs.\n",
      "Epoch: 70\n",
      "Try:1, Epoch:70, D_Loss_Real=0.660, D_Loss_Fake=0.692, D_Acc_Real=0.633, D_Acc_Fake=0.469, GAN_Loss=0.761\n",
      "\n",
      "Epoch: 71\n",
      "Try:1, Epoch:71, D_Loss_Real=0.653, D_Loss_Fake=0.578, D_Acc_Real=0.641, D_Acc_Fake=0.781, GAN_Loss=0.955\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 72\n",
      "Try:1, Epoch:72, D_Loss_Real=0.683, D_Loss_Fake=0.695, D_Acc_Real=0.578, D_Acc_Fake=0.523, GAN_Loss=0.862\n",
      "\n",
      "Epoch: 73\n",
      "Try:1, Epoch:73, D_Loss_Real=0.666, D_Loss_Fake=0.679, D_Acc_Real=0.602, D_Acc_Fake=0.609, GAN_Loss=0.827\n",
      "\n",
      "Epoch: 74\n",
      "Try:1, Epoch:74, D_Loss_Real=0.737, D_Loss_Fake=0.731, D_Acc_Real=0.484, D_Acc_Fake=0.469, GAN_Loss=0.788\n",
      "\n",
      "Epoch: 75\n",
      "Try:1, Epoch:75, D_Loss_Real=0.615, D_Loss_Fake=0.690, D_Acc_Real=0.711, D_Acc_Fake=0.531, GAN_Loss=0.827\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 76\n",
      "Try:1, Epoch:76, D_Loss_Real=0.695, D_Loss_Fake=0.512, D_Acc_Real=0.484, D_Acc_Fake=0.906, GAN_Loss=1.073\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 77\n",
      "Try:1, Epoch:77, D_Loss_Real=0.591, D_Loss_Fake=0.601, D_Acc_Real=0.625, D_Acc_Fake=0.742, GAN_Loss=0.916\n",
      "\n",
      "Epoch: 78\n",
      "Try:1, Epoch:78, D_Loss_Real=0.773, D_Loss_Fake=0.488, D_Acc_Real=0.383, D_Acc_Fake=0.922, GAN_Loss=1.086\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 79\n",
      "Try:1, Epoch:79, D_Loss_Real=0.603, D_Loss_Fake=0.722, D_Acc_Real=0.727, D_Acc_Fake=0.500, GAN_Loss=0.766\n",
      "\n",
      "Epoch: 80\n",
      "Try:1, Epoch:80, D_Loss_Real=0.718, D_Loss_Fake=0.651, D_Acc_Real=0.484, D_Acc_Fake=0.664, GAN_Loss=0.893\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Performance test> Accuracy real: 39%, fake: 71%\n",
      "(100, 32, 32, 3)\n",
      "0.0007019043\n",
      "254.99905\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch: 81\n",
      "Try:1, Epoch:81, D_Loss_Real=0.591, D_Loss_Fake=0.731, D_Acc_Real=0.711, D_Acc_Fake=0.438, GAN_Loss=0.807\n",
      "\n",
      "Epoch: 82\n",
      "Try:1, Epoch:82, D_Loss_Real=0.801, D_Loss_Fake=0.623, D_Acc_Real=0.398, D_Acc_Fake=0.680, GAN_Loss=0.917\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 83\n",
      "Try:1, Epoch:83, D_Loss_Real=0.709, D_Loss_Fake=0.750, D_Acc_Real=0.477, D_Acc_Fake=0.438, GAN_Loss=0.825\n",
      "\n",
      "Epoch: 84\n",
      "Try:1, Epoch:84, D_Loss_Real=0.606, D_Loss_Fake=0.661, D_Acc_Real=0.656, D_Acc_Fake=0.656, GAN_Loss=0.810\n",
      "\n",
      "Epoch: 85\n",
      "Try:1, Epoch:85, D_Loss_Real=0.766, D_Loss_Fake=0.514, D_Acc_Real=0.328, D_Acc_Fake=0.891, GAN_Loss=1.078\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 86\n",
      "Try:1, Epoch:86, D_Loss_Real=0.588, D_Loss_Fake=0.658, D_Acc_Real=0.688, D_Acc_Fake=0.656, GAN_Loss=0.813\n",
      "\n",
      "Epoch: 87\n",
      "Try:1, Epoch:87, D_Loss_Real=0.705, D_Loss_Fake=0.619, D_Acc_Real=0.484, D_Acc_Fake=0.727, GAN_Loss=0.897\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 88\n",
      "Try:1, Epoch:88, D_Loss_Real=0.723, D_Loss_Fake=0.593, D_Acc_Real=0.430, D_Acc_Fake=0.742, GAN_Loss=0.948\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 89\n",
      "Try:1, Epoch:89, D_Loss_Real=0.633, D_Loss_Fake=0.656, D_Acc_Real=0.617, D_Acc_Fake=0.648, GAN_Loss=0.801\n",
      "\n",
      "Epoch: 90\n",
      "Try:1, Epoch:90, D_Loss_Real=0.627, D_Loss_Fake=0.687, D_Acc_Real=0.656, D_Acc_Fake=0.562, GAN_Loss=0.851\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 91\n",
      "Try:1, Epoch:91, D_Loss_Real=0.683, D_Loss_Fake=0.731, D_Acc_Real=0.609, D_Acc_Fake=0.461, GAN_Loss=0.920\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 92\n",
      "Try:1, Epoch:92, D_Loss_Real=0.647, D_Loss_Fake=0.539, D_Acc_Real=0.617, D_Acc_Fake=0.844, GAN_Loss=0.991\n",
      "\n",
      "Generator loss increased for 3 epochs.\n",
      "Epoch: 93\n",
      "Try:1, Epoch:93, D_Loss_Real=0.785, D_Loss_Fake=0.709, D_Acc_Real=0.414, D_Acc_Fake=0.500, GAN_Loss=0.782\n",
      "\n",
      "Epoch: 94\n",
      "Try:1, Epoch:94, D_Loss_Real=0.630, D_Loss_Fake=0.650, D_Acc_Real=0.625, D_Acc_Fake=0.633, GAN_Loss=0.849\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 95\n",
      "Try:1, Epoch:95, D_Loss_Real=0.712, D_Loss_Fake=0.651, D_Acc_Real=0.508, D_Acc_Fake=0.625, GAN_Loss=0.883\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 96\n",
      "Try:1, Epoch:96, D_Loss_Real=0.596, D_Loss_Fake=0.545, D_Acc_Real=0.672, D_Acc_Fake=0.828, GAN_Loss=1.005\n",
      "\n",
      "Generator loss increased for 3 epochs.\n",
      "Epoch: 97\n",
      "Try:1, Epoch:97, D_Loss_Real=0.666, D_Loss_Fake=0.697, D_Acc_Real=0.602, D_Acc_Fake=0.555, GAN_Loss=0.778\n",
      "\n",
      "Epoch: 98\n",
      "Try:1, Epoch:98, D_Loss_Real=0.646, D_Loss_Fake=0.676, D_Acc_Real=0.578, D_Acc_Fake=0.609, GAN_Loss=0.920\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 99\n",
      "Try:1, Epoch:99, D_Loss_Real=0.597, D_Loss_Fake=0.623, D_Acc_Real=0.664, D_Acc_Fake=0.633, GAN_Loss=0.871\n",
      "\n",
      "Epoch: 100\n",
      "Try:1, Epoch:100, D_Loss_Real=0.741, D_Loss_Fake=0.683, D_Acc_Real=0.398, D_Acc_Fake=0.547, GAN_Loss=0.871\n",
      "\n",
      "Performance test> Accuracy real: 54%, fake: 66%\n",
      "(100, 32, 32, 3)\n",
      "5.340576e-05\n",
      "254.99994\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch: 101\n",
      "Try:1, Epoch:101, D_Loss_Real=0.786, D_Loss_Fake=0.630, D_Acc_Real=0.383, D_Acc_Fake=0.641, GAN_Loss=0.962\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 102\n",
      "Try:1, Epoch:102, D_Loss_Real=0.627, D_Loss_Fake=0.773, D_Acc_Real=0.625, D_Acc_Fake=0.422, GAN_Loss=0.726\n",
      "\n",
      "Epoch: 103\n",
      "Try:1, Epoch:103, D_Loss_Real=0.717, D_Loss_Fake=0.639, D_Acc_Real=0.469, D_Acc_Fake=0.625, GAN_Loss=0.900\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 104\n",
      "Try:1, Epoch:104, D_Loss_Real=0.678, D_Loss_Fake=0.650, D_Acc_Real=0.523, D_Acc_Fake=0.609, GAN_Loss=0.869\n",
      "\n",
      "Epoch: 105\n",
      "Try:1, Epoch:105, D_Loss_Real=0.584, D_Loss_Fake=0.679, D_Acc_Real=0.758, D_Acc_Fake=0.570, GAN_Loss=0.819\n",
      "\n",
      "Epoch: 106\n",
      "Try:1, Epoch:106, D_Loss_Real=0.758, D_Loss_Fake=0.582, D_Acc_Real=0.453, D_Acc_Fake=0.750, GAN_Loss=0.991\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 107\n",
      "Try:1, Epoch:107, D_Loss_Real=0.626, D_Loss_Fake=0.625, D_Acc_Real=0.633, D_Acc_Fake=0.719, GAN_Loss=0.899\n",
      "\n",
      "Epoch: 108\n",
      "Try:1, Epoch:108, D_Loss_Real=0.690, D_Loss_Fake=0.542, D_Acc_Real=0.508, D_Acc_Fake=0.898, GAN_Loss=0.980\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 109\n",
      "Try:1, Epoch:109, D_Loss_Real=0.660, D_Loss_Fake=0.696, D_Acc_Real=0.578, D_Acc_Fake=0.531, GAN_Loss=0.846\n",
      "\n",
      "Epoch: 110\n",
      "Try:1, Epoch:110, D_Loss_Real=0.718, D_Loss_Fake=0.696, D_Acc_Real=0.516, D_Acc_Fake=0.562, GAN_Loss=0.889\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try:1, Epoch:111, D_Loss_Real=0.615, D_Loss_Fake=0.699, D_Acc_Real=0.664, D_Acc_Fake=0.516, GAN_Loss=0.765\n",
      "\n",
      "Epoch: 112\n",
      "Try:1, Epoch:112, D_Loss_Real=0.731, D_Loss_Fake=0.701, D_Acc_Real=0.469, D_Acc_Fake=0.562, GAN_Loss=0.846\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 113\n",
      "Try:1, Epoch:113, D_Loss_Real=0.630, D_Loss_Fake=0.734, D_Acc_Real=0.641, D_Acc_Fake=0.484, GAN_Loss=0.767\n",
      "\n",
      "Epoch: 114\n",
      "Try:1, Epoch:114, D_Loss_Real=0.668, D_Loss_Fake=0.673, D_Acc_Real=0.539, D_Acc_Fake=0.578, GAN_Loss=0.824\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 115\n",
      "Try:1, Epoch:115, D_Loss_Real=0.743, D_Loss_Fake=0.648, D_Acc_Real=0.461, D_Acc_Fake=0.641, GAN_Loss=0.908\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 116\n",
      "Try:1, Epoch:116, D_Loss_Real=0.627, D_Loss_Fake=0.676, D_Acc_Real=0.672, D_Acc_Fake=0.594, GAN_Loss=0.818\n",
      "\n",
      "Epoch: 117\n",
      "Try:1, Epoch:117, D_Loss_Real=0.723, D_Loss_Fake=0.769, D_Acc_Real=0.469, D_Acc_Fake=0.398, GAN_Loss=0.713\n",
      "\n",
      "Epoch: 118\n",
      "Try:1, Epoch:118, D_Loss_Real=0.790, D_Loss_Fake=0.624, D_Acc_Real=0.344, D_Acc_Fake=0.680, GAN_Loss=0.893\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 119\n",
      "Try:1, Epoch:119, D_Loss_Real=0.632, D_Loss_Fake=0.710, D_Acc_Real=0.641, D_Acc_Fake=0.516, GAN_Loss=0.804\n",
      "\n",
      "Epoch: 120\n",
      "Try:1, Epoch:120, D_Loss_Real=0.724, D_Loss_Fake=0.625, D_Acc_Real=0.477, D_Acc_Fake=0.727, GAN_Loss=0.888\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Performance test> Accuracy real: 42%, fake: 92%\n",
      "(100, 32, 32, 3)\n",
      "0.0024414062\n",
      "254.99841\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch: 121\n",
      "Try:1, Epoch:121, D_Loss_Real=0.657, D_Loss_Fake=0.700, D_Acc_Real=0.570, D_Acc_Fake=0.492, GAN_Loss=0.841\n",
      "\n",
      "Epoch: 122\n",
      "Try:1, Epoch:122, D_Loss_Real=0.744, D_Loss_Fake=0.636, D_Acc_Real=0.477, D_Acc_Fake=0.688, GAN_Loss=0.932\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 123\n",
      "Try:1, Epoch:123, D_Loss_Real=0.704, D_Loss_Fake=0.606, D_Acc_Real=0.586, D_Acc_Fake=0.656, GAN_Loss=0.982\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 124\n",
      "Try:1, Epoch:124, D_Loss_Real=0.505, D_Loss_Fake=0.678, D_Acc_Real=0.797, D_Acc_Fake=0.562, GAN_Loss=0.814\n",
      "\n",
      "Epoch: 125\n",
      "Try:1, Epoch:125, D_Loss_Real=0.745, D_Loss_Fake=0.724, D_Acc_Real=0.422, D_Acc_Fake=0.461, GAN_Loss=0.780\n",
      "\n",
      "Epoch: 126\n",
      "Try:1, Epoch:126, D_Loss_Real=0.698, D_Loss_Fake=0.649, D_Acc_Real=0.492, D_Acc_Fake=0.594, GAN_Loss=0.971\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 127\n",
      "Try:1, Epoch:127, D_Loss_Real=0.682, D_Loss_Fake=0.649, D_Acc_Real=0.539, D_Acc_Fake=0.695, GAN_Loss=0.833\n",
      "\n",
      "Epoch: 128\n",
      "Try:1, Epoch:128, D_Loss_Real=0.700, D_Loss_Fake=0.623, D_Acc_Real=0.523, D_Acc_Fake=0.656, GAN_Loss=0.901\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 129\n",
      "Try:1, Epoch:129, D_Loss_Real=0.707, D_Loss_Fake=0.701, D_Acc_Real=0.445, D_Acc_Fake=0.523, GAN_Loss=0.802\n",
      "\n",
      "Epoch: 130\n",
      "Try:1, Epoch:130, D_Loss_Real=0.642, D_Loss_Fake=0.722, D_Acc_Real=0.633, D_Acc_Fake=0.508, GAN_Loss=0.769\n",
      "\n",
      "Epoch: 131\n",
      "Try:1, Epoch:131, D_Loss_Real=0.644, D_Loss_Fake=0.643, D_Acc_Real=0.648, D_Acc_Fake=0.656, GAN_Loss=0.805\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 132\n",
      "Try:1, Epoch:132, D_Loss_Real=0.778, D_Loss_Fake=0.750, D_Acc_Real=0.398, D_Acc_Fake=0.508, GAN_Loss=0.851\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 133\n",
      "Try:1, Epoch:133, D_Loss_Real=0.667, D_Loss_Fake=0.713, D_Acc_Real=0.570, D_Acc_Fake=0.531, GAN_Loss=0.819\n",
      "\n",
      "Epoch: 134\n",
      "Try:1, Epoch:134, D_Loss_Real=0.668, D_Loss_Fake=0.663, D_Acc_Real=0.555, D_Acc_Fake=0.570, GAN_Loss=0.786\n",
      "\n",
      "Epoch: 135\n",
      "Try:1, Epoch:135, D_Loss_Real=0.635, D_Loss_Fake=0.696, D_Acc_Real=0.680, D_Acc_Fake=0.516, GAN_Loss=0.807\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 136\n",
      "Try:1, Epoch:136, D_Loss_Real=0.687, D_Loss_Fake=0.718, D_Acc_Real=0.547, D_Acc_Fake=0.484, GAN_Loss=0.841\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 137\n",
      "Try:1, Epoch:137, D_Loss_Real=0.693, D_Loss_Fake=0.671, D_Acc_Real=0.477, D_Acc_Fake=0.570, GAN_Loss=0.846\n",
      "\n",
      "Generator loss increased for 3 epochs.\n",
      "Epoch: 138\n",
      "Try:1, Epoch:138, D_Loss_Real=0.655, D_Loss_Fake=0.695, D_Acc_Real=0.594, D_Acc_Fake=0.547, GAN_Loss=0.806\n",
      "\n",
      "Epoch: 139\n",
      "Try:1, Epoch:139, D_Loss_Real=0.653, D_Loss_Fake=0.734, D_Acc_Real=0.547, D_Acc_Fake=0.430, GAN_Loss=0.787\n",
      "\n",
      "Epoch: 140\n",
      "Try:1, Epoch:140, D_Loss_Real=0.724, D_Loss_Fake=0.614, D_Acc_Real=0.484, D_Acc_Fake=0.711, GAN_Loss=0.954\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Performance test> Accuracy real: 45%, fake: 76%\n",
      "(100, 32, 32, 3)\n",
      "0.0022735596\n",
      "254.99812\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch: 141\n",
      "Try:1, Epoch:141, D_Loss_Real=0.752, D_Loss_Fake=0.653, D_Acc_Real=0.383, D_Acc_Fake=0.633, GAN_Loss=0.896\n",
      "\n",
      "Epoch: 142\n",
      "Try:1, Epoch:142, D_Loss_Real=0.711, D_Loss_Fake=0.692, D_Acc_Real=0.539, D_Acc_Fake=0.570, GAN_Loss=0.858\n",
      "\n",
      "Epoch: 143\n",
      "Try:1, Epoch:143, D_Loss_Real=0.671, D_Loss_Fake=0.680, D_Acc_Real=0.531, D_Acc_Fake=0.594, GAN_Loss=0.810\n",
      "\n",
      "Epoch: 144\n",
      "Try:1, Epoch:144, D_Loss_Real=0.671, D_Loss_Fake=0.726, D_Acc_Real=0.641, D_Acc_Fake=0.492, GAN_Loss=0.816\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 145\n",
      "Try:1, Epoch:145, D_Loss_Real=0.601, D_Loss_Fake=0.706, D_Acc_Real=0.672, D_Acc_Fake=0.508, GAN_Loss=0.843\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 146\n",
      "Try:1, Epoch:146, D_Loss_Real=0.561, D_Loss_Fake=0.732, D_Acc_Real=0.750, D_Acc_Fake=0.469, GAN_Loss=0.793\n",
      "\n",
      "Epoch: 147\n",
      "Try:1, Epoch:147, D_Loss_Real=0.692, D_Loss_Fake=0.626, D_Acc_Real=0.523, D_Acc_Fake=0.656, GAN_Loss=0.966\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 148\n",
      "Try:1, Epoch:148, D_Loss_Real=0.733, D_Loss_Fake=0.511, D_Acc_Real=0.445, D_Acc_Fake=0.867, GAN_Loss=1.143\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 149\n",
      "Try:1, Epoch:149, D_Loss_Real=0.720, D_Loss_Fake=0.737, D_Acc_Real=0.500, D_Acc_Fake=0.508, GAN_Loss=0.786\n",
      "\n",
      "Epoch: 150\n",
      "Try:1, Epoch:150, D_Loss_Real=0.751, D_Loss_Fake=0.649, D_Acc_Real=0.469, D_Acc_Fake=0.672, GAN_Loss=0.857\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 151\n",
      "Try:1, Epoch:151, D_Loss_Real=0.664, D_Loss_Fake=0.796, D_Acc_Real=0.562, D_Acc_Fake=0.328, GAN_Loss=0.744\n",
      "\n",
      "Epoch: 152\n",
      "Try:1, Epoch:152, D_Loss_Real=0.676, D_Loss_Fake=0.675, D_Acc_Real=0.555, D_Acc_Fake=0.562, GAN_Loss=0.848\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 153\n",
      "Try:1, Epoch:153, D_Loss_Real=0.715, D_Loss_Fake=0.785, D_Acc_Real=0.508, D_Acc_Fake=0.289, GAN_Loss=0.699\n",
      "\n",
      "Epoch: 154\n",
      "Try:1, Epoch:154, D_Loss_Real=0.704, D_Loss_Fake=0.653, D_Acc_Real=0.508, D_Acc_Fake=0.609, GAN_Loss=0.831\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 155\n",
      "Try:1, Epoch:155, D_Loss_Real=0.703, D_Loss_Fake=0.778, D_Acc_Real=0.508, D_Acc_Fake=0.320, GAN_Loss=0.744\n",
      "\n",
      "Epoch: 156\n",
      "Try:1, Epoch:156, D_Loss_Real=0.724, D_Loss_Fake=0.677, D_Acc_Real=0.445, D_Acc_Fake=0.594, GAN_Loss=0.807\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 157\n",
      "Try:1, Epoch:157, D_Loss_Real=0.682, D_Loss_Fake=0.659, D_Acc_Real=0.555, D_Acc_Fake=0.594, GAN_Loss=0.877\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 158\n",
      "Try:1, Epoch:158, D_Loss_Real=0.667, D_Loss_Fake=0.727, D_Acc_Real=0.586, D_Acc_Fake=0.445, GAN_Loss=0.738\n",
      "\n",
      "Epoch: 159\n",
      "Try:1, Epoch:159, D_Loss_Real=0.703, D_Loss_Fake=0.725, D_Acc_Real=0.508, D_Acc_Fake=0.492, GAN_Loss=0.767\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 160\n",
      "Try:1, Epoch:160, D_Loss_Real=0.711, D_Loss_Fake=0.714, D_Acc_Real=0.461, D_Acc_Fake=0.523, GAN_Loss=0.793\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Performance test> Accuracy real: 45%, fake: 60%\n",
      "(100, 32, 32, 3)\n",
      "0.049240112\n",
      "254.99692\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch: 161\n",
      "Try:1, Epoch:161, D_Loss_Real=0.632, D_Loss_Fake=0.720, D_Acc_Real=0.648, D_Acc_Fake=0.500, GAN_Loss=0.750\n",
      "\n",
      "Epoch: 162\n",
      "Try:1, Epoch:162, D_Loss_Real=0.689, D_Loss_Fake=0.635, D_Acc_Real=0.547, D_Acc_Fake=0.688, GAN_Loss=0.810\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 163\n",
      "Try:1, Epoch:163, D_Loss_Real=0.684, D_Loss_Fake=0.691, D_Acc_Real=0.578, D_Acc_Fake=0.547, GAN_Loss=0.784\n",
      "\n",
      "Epoch: 164\n",
      "Try:1, Epoch:164, D_Loss_Real=0.773, D_Loss_Fake=0.769, D_Acc_Real=0.359, D_Acc_Fake=0.344, GAN_Loss=0.739\n",
      "\n",
      "Epoch: 165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try:1, Epoch:165, D_Loss_Real=0.643, D_Loss_Fake=0.717, D_Acc_Real=0.664, D_Acc_Fake=0.516, GAN_Loss=0.772\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 166\n",
      "Try:1, Epoch:166, D_Loss_Real=0.700, D_Loss_Fake=0.660, D_Acc_Real=0.500, D_Acc_Fake=0.641, GAN_Loss=0.788\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 167\n",
      "Try:1, Epoch:167, D_Loss_Real=0.784, D_Loss_Fake=0.622, D_Acc_Real=0.383, D_Acc_Fake=0.680, GAN_Loss=0.906\n",
      "\n",
      "Generator loss increased for 3 epochs.\n",
      "Epoch: 168\n",
      "Try:1, Epoch:168, D_Loss_Real=0.674, D_Loss_Fake=0.689, D_Acc_Real=0.562, D_Acc_Fake=0.547, GAN_Loss=0.794\n",
      "\n",
      "Epoch: 169\n",
      "Try:1, Epoch:169, D_Loss_Real=0.718, D_Loss_Fake=0.685, D_Acc_Real=0.492, D_Acc_Fake=0.570, GAN_Loss=0.809\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 170\n",
      "Try:1, Epoch:170, D_Loss_Real=0.667, D_Loss_Fake=0.672, D_Acc_Real=0.617, D_Acc_Fake=0.609, GAN_Loss=0.820\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 171\n",
      "Try:1, Epoch:171, D_Loss_Real=0.694, D_Loss_Fake=0.628, D_Acc_Real=0.500, D_Acc_Fake=0.711, GAN_Loss=0.871\n",
      "\n",
      "Generator loss increased for 3 epochs.\n",
      "Epoch: 172\n",
      "Try:1, Epoch:172, D_Loss_Real=0.689, D_Loss_Fake=0.702, D_Acc_Real=0.539, D_Acc_Fake=0.484, GAN_Loss=0.775\n",
      "\n",
      "Epoch: 173\n",
      "Try:1, Epoch:173, D_Loss_Real=0.661, D_Loss_Fake=0.717, D_Acc_Real=0.594, D_Acc_Fake=0.477, GAN_Loss=0.752\n",
      "\n",
      "Epoch: 174\n",
      "Try:1, Epoch:174, D_Loss_Real=0.660, D_Loss_Fake=0.758, D_Acc_Real=0.602, D_Acc_Fake=0.336, GAN_Loss=0.700\n",
      "\n",
      "Epoch: 175\n",
      "Try:1, Epoch:175, D_Loss_Real=0.725, D_Loss_Fake=0.710, D_Acc_Real=0.383, D_Acc_Fake=0.453, GAN_Loss=0.795\n",
      "\n",
      "Generator loss increased for 1 epochs.\n",
      "Epoch: 176\n",
      "Try:1, Epoch:176, D_Loss_Real=0.661, D_Loss_Fake=0.658, D_Acc_Real=0.594, D_Acc_Fake=0.609, GAN_Loss=0.805\n",
      "\n",
      "Generator loss increased for 2 epochs.\n",
      "Epoch: 177\n",
      "Try:1, Epoch:177, D_Loss_Real=0.717, D_Loss_Fake=0.771, D_Acc_Real=0.414, D_Acc_Fake=0.359, GAN_Loss=0.717\n",
      "\n",
      "Epoch: 178\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gantrainer \u001b[38;5;241m=\u001b[39m \u001b[43mGANTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcifar10\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./cifar10/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatchsize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmax_loss_increase_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Assignments\\DSA5204\\Project\\gantrainer.py:80\u001b[0m, in \u001b[0;36mGANTrainer.__init__\u001b[1;34m(self, datasettype, savepath, latent_dim, n_epochs, batchsize, retries, max_loss_increase_epochs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test \u001b[38;5;241m=\u001b[39m y_test\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining GAN with\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlatent_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Latent Dimensions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Epochs\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-with Batch Size of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatchsize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-up to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Retries\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 80\u001b[0m g_model, d_model, gan_model, d_loss_real, d_loss_fake, d_acc_real, d_acc_fake, g_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatchsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator \u001b[38;5;241m=\u001b[39m g_model\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscriminator \u001b[38;5;241m=\u001b[39m d_model\n",
      "File \u001b[1;32mD:\\Assignments\\DSA5204\\Project\\gantrainer.py:278\u001b[0m, in \u001b[0;36mGANTrainer.train\u001b[1;34m(self, dataset, latent_dim, n_epochs, batchsize, retries)\u001b[0m\n\u001b[0;32m    276\u001b[0m X_real, y_real \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen_real(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_train, half_batch)\n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m# generate 'fake' examples\u001b[39;00m\n\u001b[1;32m--> 278\u001b[0m X_fake, y_fake \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_fake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhalf_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;66;03m# update discriminator model weights\u001b[39;00m\n\u001b[0;32m    280\u001b[0m d_l_real, d_a_real \u001b[38;5;241m=\u001b[39m d_model\u001b[38;5;241m.\u001b[39mtrain_on_batch(X_real, y_real)\n",
      "File \u001b[1;32mD:\\Assignments\\DSA5204\\Project\\gantrainer.py:202\u001b[0m, in \u001b[0;36mGANTrainer.gen_fake\u001b[1;34m(self, g_model, latent_dim, n_samples)\u001b[0m\n\u001b[0;32m    200\u001b[0m x_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_latent(latent_dim, n_samples)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m# predict outputs\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mg_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m# create 'fake' class labels (0)\u001b[39;00m\n\u001b[0;32m    204\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((n_samples, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1951\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1944\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   1945\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1946\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy or \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1947\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTPUStrategy and AutoShardPolicy.FILE might lead to out-of-order \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1948\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult. Consider setting it to AutoShardPolicy.DATA.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1949\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m-> 1951\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1953\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1954\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1955\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1959\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1961\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1963\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   1964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\data_adapter.py:1399\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1398\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1399\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\data_adapter.py:1149\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1146\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[0;32m   1148\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1163\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\data_adapter.py:326\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m     flat_dataset \u001b[38;5;241m=\u001b[39m flat_dataset\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m1024\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(epochs)\n\u001b[0;32m    324\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m--> 326\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mindices_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_batch_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslice_inputs(indices_dataset, inputs)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2060\u001b[0m, in \u001b[0;36mDatasetV2.flat_map\u001b[1;34m(self, map_func, name)\u001b[0m\n\u001b[0;32m   2026\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_map\u001b[39m(\u001b[38;5;28mself\u001b[39m, map_func, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2027\u001b[0m   \u001b[38;5;124;03m\"\"\"Maps `map_func` across this dataset and flattens the result.\u001b[39;00m\n\u001b[0;32m   2028\u001b[0m \n\u001b[0;32m   2029\u001b[0m \u001b[38;5;124;03m  The type signature is:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2058\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[0;32m   2059\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2060\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFlatMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5279\u001b[0m, in \u001b[0;36mFlatMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[0;32m   5277\u001b[0m \u001b[38;5;124;03m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m   5278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[1;32m-> 5279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure, DatasetSpec):\n\u001b[0;32m   5282\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   5283\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `map_func` argument must return a `Dataset` object. Got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5284\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_get_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure)\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    265\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    268\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    269\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3070\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   3062\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m   3063\u001b[0m \n\u001b[0;32m   3064\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3068\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m   3069\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3070\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concrete_function_garbage_collected(\n\u001b[0;32m   3071\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3072\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   3073\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3036\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3034\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3035\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 3036\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3037\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m   3038\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m   3039\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3292\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3288\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[0;32m   3289\u001b[0m       args, kwargs, flat_args, filtered_flat_args)\n\u001b[0;32m   3291\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd_call_context(cache_key\u001b[38;5;241m.\u001b[39mcall_context)\n\u001b[1;32m-> 3292\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[0;32m   3294\u001b[0m                          graph_function)\n\u001b[0;32m   3296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3130\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3125\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   3127\u001b[0m ]\n\u001b[0;32m   3128\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   3129\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 3130\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3133\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3135\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3138\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3139\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   3141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   3142\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   3143\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   3144\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   3145\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   3146\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   3147\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1044\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1042\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(op_return_value, ops\u001b[38;5;241m.\u001b[39mTensor), op_return_value\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1044\u001b[0m   func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mFuncGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1045\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapture_by_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_graph, FuncGraph)\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_control_dependencies:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:195\u001b[0m, in \u001b[0;36mFuncGraph.__init__\u001b[1;34m(self, name, collections, capture_by_value, structured_input_signature, structured_outputs)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, collections\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, capture_by_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    170\u001b[0m              structured_input_signature\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, structured_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    171\u001b[0m   \u001b[38;5;124;03m\"\"\"Construct a new FuncGraph.\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03m  The graph will inherit its graph key, collections, seed, and distribution\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;124;03m      information.\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 195\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFuncGraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m    197\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3192\u001b[0m, in \u001b[0;36mGraph.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3188\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduced_shape_cache \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   3190\u001b[0m \u001b[38;5;66;03m# TODO(skyewm): fold as much of the above as possible into the C\u001b[39;00m\n\u001b[0;32m   3191\u001b[0m \u001b[38;5;66;03m# implementation\u001b[39;00m\n\u001b[1;32m-> 3192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scoped_c_graph \u001b[38;5;241m=\u001b[39m \u001b[43mc_api_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mScopedTFGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3193\u001b[0m \u001b[38;5;66;03m# The C API requires all ops to have shape functions. Disable this\u001b[39;00m\n\u001b[0;32m   3194\u001b[0m \u001b[38;5;66;03m# requirement (many custom ops do not have shape functions, and we don't\u001b[39;00m\n\u001b[0;32m   3195\u001b[0m \u001b[38;5;66;03m# want to break these existing cases).\u001b[39;00m\n\u001b[0;32m   3196\u001b[0m pywrap_tf_session\u001b[38;5;241m.\u001b[39mSetRequireShapeInferenceFns(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c_graph, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\c_api_util.py:46\u001b[0m, in \u001b[0;36mScopedTFGraph.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 46\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;241m=\u001b[39m \u001b[43mc_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_NewGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m   \u001b[38;5;66;03m# Note: when we're destructing the global context (i.e when the process is\u001b[39;00m\n\u001b[0;32m     48\u001b[0m   \u001b[38;5;66;03m# terminating) we may have already deleted other modules. By capturing the\u001b[39;00m\n\u001b[0;32m     49\u001b[0m   \u001b[38;5;66;03m# DeleteGraph function here, we retain the ability to cleanly destroy the\u001b[39;00m\n\u001b[0;32m     50\u001b[0m   \u001b[38;5;66;03m# graph at shutdown, which satisfies leak checkers.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeleter \u001b[38;5;241m=\u001b[39m c_api\u001b[38;5;241m.\u001b[39mTF_DeleteGraph\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gantrainer = GANTrainer('cifar10', './cifar10/', latent_dim = 100, \n",
    "                        n_epochs = 1000, batchsize = 256, retries = 5, \n",
    "                        max_loss_increase_epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea25cc1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
